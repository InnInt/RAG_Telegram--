# rag_pipeline.py
import os
import pickle
import sqlite3
import faiss
import tiktoken
import hashlib
import requests
import numpy as np
from datetime import datetime
from openai import OpenAI, PermissionDeniedError, AuthenticationError, RateLimitError
from config import FAISS_INDEX_PATH, OPENAI_API_KEY, EMBEDDING_MODEL, GPT_MODEL as CHAT_MODEL, DB_PATH

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenAI
client = OpenAI(api_key=OPENAI_API_KEY)

# === –ê–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ü–µ–Ω—ã (OpenAI, –∏—é–ª—å 2025) ===
MODEL_PRICES = {
    "gpt-4o-mini": {"prompt": 0.00015, "completion": 0.00060},
    "gpt-4o": {"prompt": 0.0025, "completion": 0.0100},
    "gpt-4.5": {"prompt": 0.0050, "completion": 0.0200},
    "o1-pro": {"prompt": 0.0150, "completion": 0.0600},
    "o1-mini": {"prompt": 0.0030, "completion": 0.0120}
}

# –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ü–µ–Ω—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è gpt-4o-mini, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
current_model_prices = MODEL_PRICES.get(CHAT_MODEL, MODEL_PRICES["gpt-4o-mini"])

# === –ü–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ ===
def count_tokens(text, model=CHAT_MODEL):
    try:
        enc = tiktoken.encoding_for_model(model)
    except KeyError:
        enc = tiktoken.get_encoding("cl100kbase")
    return len(enc.encode(text))

# === –•—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è ===
def hash_query(query: str) -> str:
    return hashlib.md5(query.encode("utf-8")).hexdigest()

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (–ª–æ–≥–∏ –∑–∞–ø—Ä–æ—Å–æ–≤) ===
def init_db():
    db_dir = os.path.dirname(DB_PATH)
    if db_dir:
        os.makedirs(db_dir, exist_ok=True)

    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("""
        CREATE TABLE IF NOT EXISTS query_logs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            query TEXT UNIQUE,
            response TEXT,
            tokens_prompt INTEGER,
            tokens_completion INTEGER,
            cost_usd REAL,
            timestamp TEXT
        )
    """)
    conn.commit()
    conn.close()

# === –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞ ===
def get_cached_response(query: str):
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("SELECT response FROM query_logs WHERE query = ?", (query,))
    row = cur.fetchone()
    conn.close()
    return row[0] if row else None

# === –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ ===
def log_query(query: str, response: str, tokens_prompt: int, tokens_completion: int, cost_usd: float):
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    try:
        cur.execute("""
            INSERT OR REPLACE INTO query_logs 
            (query, response, tokens_prompt, tokens_completion, cost_usd, timestamp)
            VALUES (?, ?, ?, ?, ?, ?)
        """, (query, response, tokens_prompt, tokens_completion, cost_usd, datetime.now().isoformat()))
        conn.commit()
    except sqlite3.Error as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
    finally:
        conn.close()

# === –ó–∞–≥—Ä—É–∑–∫–∞ FAISS-–∏–Ω–¥–µ–∫—Å–∞ –∏ —á–∞–Ω–∫–æ–≤ ===
def load_faiss_index():
    index_path = os.path.join(FAISS_INDEX_PATH, "index.faiss")
    pkl_path = os.path.join(FAISS_INDEX_PATH, "index.pkl")

    if not os.path.exists(index_path):
        raise FileNotFoundError(f"FAISS –∏–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω: {index_path}")
    if not os.path.exists(pkl_path):
        raise FileNotFoundError(f"–§–∞–π–ª —á–∞–Ω–∫–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {pkl_path}")

    index = faiss.read_index(index_path)
    with open(pkl_path, "rb") as f:
        chunks = pickle.load(f)
    return index, chunks

# === –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ OpenAI ===
def embed_query(query: str):
    try:
        response = client.embeddings.create(
            model=EMBEDDING_MODEL,
            input=query
        )
        return response.data[0].embedding
    except (PermissionDeniedError, AuthenticationError, RateLimitError) as e:
        print(f"‚ùå OpenAI –æ—à–∏–±–∫–∞: {e}")
        raise
    except Exception as e:
        print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
        raise

# === –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ ===
def search_chunks(query: str, index, chunks, top_k=5):
    # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy array —Å –Ω—É–∂–Ω—ã–º —Ç–∏–ø–æ–º
    query_embedding = embed_query(query)
    query_vector = np.array([query_embedding], dtype="float32")  # ‚Üê –∫–ª—é—á–µ–≤–∞—è —Å—Ç—Ä–æ–∫–∞
    D, I = index.search(query_vector, top_k)
    return [chunks[i] for i in I[0] if i < len(chunks)]

# === –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏ ===
def generate_answer(query: str, context_chunks: list):
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
    context_text = ""
    for i, chunk in enumerate(context_chunks):
        truncated_chunk = chunk.strip()[:1000]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        context_text += f"[–ò—Å—Ç–æ—á–Ω–∏–∫ {i+1}]\n{truncated_chunk}\n\n"

    prompt = f"""–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å–µ–ª—å—Å–∫–æ–º—É —Ö–æ–∑—è–π—Å—Ç–≤—É. –û—Ç–≤–µ—á–∞–π —Ç–æ—á–Ω–æ, –∫—Ä–∞—Ç–∫–æ, –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏–≤–µ–¥—ë–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã.

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context_text}

–í–æ–ø—Ä–æ—Å: {query}
–û—Ç–≤–µ—Ç:"""

    tokens_prompt = count_tokens(prompt)

    try:
        completion = client.chat.completions.create(
            model=CHAT_MODEL,
            messages=[
                {"role": "system", "content": "–¢—ã ‚Äî –∞–≥—Ä–æ–Ω–æ–º-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç. –û—Ç–≤–µ—á–∞–π —Ç–æ—á–Ω–æ, –Ω–∞ —Ä—É—Å—Å–∫–æ–º."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=512,
            temperature=0.3
        )

        answer = completion.choices[0].message.content.strip()
        tokens_completion = completion.usage.completion_tokens
        total_tokens = completion.usage.total_tokens

        # –†–∞—Å—á—ë—Ç —Å—Ç–æ–∏–º–æ—Å—Ç–∏
        cost_usd = (
            (tokens_prompt / 1000) * current_model_prices["prompt"] +
            (tokens_completion / 1000) * current_model_prices["completion"]
        )

        log_query(query, answer, tokens_prompt, tokens_completion, cost_usd)

        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ –æ—Ç–≤–µ—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        answer += f"\n\n‚ÑπÔ∏è –û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ {len(context_chunks)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤. –°—Ç–æ–∏–º–æ—Å—Ç—å: ${cost_usd:.4f}"

        return answer, tokens_prompt, tokens_completion, cost_usd

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        fallback = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –∏–∑-–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –æ—à–∏–±–∫–∏."
        log_query(query, fallback, 0, 0, 0.0)
        return fallback, 0, 0, 0.0

# === –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è RAG ===
def get_answer(query: str) -> str:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –±–æ—Ç–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫—É ‚Äî –æ—Ç–≤–µ—Ç.
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
    cached = get_cached_response(query)
    if cached:
        print("üîÅ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à")
        return cached

    try:
        index, chunks = load_faiss_index()
        context_chunks = search_chunks(query, index, chunks, top_k=5)
        if not context_chunks:
            return "‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É."

        answer, _, _, _ = generate_answer(query, context_chunks)
        return answer

    except FileNotFoundError as e:
        return f"‚ùå –û—à–∏–±–∫–∞: {e}. –ó–∞–ø—É—Å—Ç–∏—Ç–µ create_index.py."
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ get_answer: {e}")
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞."

# === CLI-—Ä–µ–∂–∏–º –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è ===
if __name__ == "__main__":
    init_db()
    print("üí° RAG-—Å–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞. –í–≤–µ–¥–∏—Ç–µ '–≤—ã—Ö–æ–¥', —á—Ç–æ–±—ã –∑–∞–≤–µ—Ä—à–∏—Ç—å.")

    while True:
        try:
            user_query = input("\n‚ùì –í–æ–ø—Ä–æ—Å: ").strip()
            if not user_query:
                continue
            if user_query.lower() in ["–≤—ã—Ö–æ–¥", "exit", "quit"]:
                print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                break

            answer = get_answer(user_query)
            print(f"\nüí¨ –û—Ç–≤–µ—Ç: {answer}")

        except KeyboardInterrupt:
            print("\nüëã –ó–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É...")
            break
        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")